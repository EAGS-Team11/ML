{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2667,"databundleVersionId":29898,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# SEL 1: Setup & Install Dependencies\n\n!pip uninstall -y transformers evaluate datasets huggingface_hub gradio\n!pip install openai\n!pip install keybert\n!pip install --no-cache-dir \\\n    transformers==4.44.2 \\\n    evaluate==0.4.2 \\\n    datasets==3.0.2 \\\n    ipywidgets==8.1.1 \\\n    sentence_transformers \\\n    gradio \\\n    \"huggingface_hub>=0.33.5\" \\\n    typing_extensions\n\nprint(\"--- Instalasi Selesai ---\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:02:39.939679Z","iopub.execute_input":"2025-11-27T00:02:39.939939Z","iopub.status.idle":"2025-11-27T00:03:09.199275Z","shell.execute_reply.started":"2025-11-27T00:02:39.939919Z","shell.execute_reply":"2025-11-27T00:03:09.198270Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.44.2\nUninstalling transformers-4.44.2:\n  Successfully uninstalled transformers-4.44.2\nFound existing installation: evaluate 0.4.2\nUninstalling evaluate-0.4.2:\n  Successfully uninstalled evaluate-0.4.2\nFound existing installation: datasets 3.0.2\nUninstalling datasets-3.0.2:\n  Successfully uninstalled datasets-3.0.2\nFound existing installation: huggingface-hub 0.36.0\nUninstalling huggingface-hub-0.36.0:\n  Successfully uninstalled huggingface-hub-0.36.0\nFound existing installation: gradio 6.0.1\nUninstalling gradio-6.0.1:\n  Successfully uninstalled gradio-6.0.1\nRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (2.7.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.11.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.12.4)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.15.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\nRequirement already satisfied: keybert in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.26.4)\nRequirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (14.2.0)\nRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.2.2)\nRequirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from keybert) (4.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->keybert) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->keybert) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->keybert) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->keybert) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->keybert) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->keybert) (2.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.19.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.6.0)\nCollecting transformers<5.0.0,>=4.41.0 (from sentence-transformers>=0.3.8->keybert)\n  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.6.0+cu124)\nCollecting huggingface-hub>=0.20.0 (from sentence-transformers>=0.3.8->keybert)\n  Using cached huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.15.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.9.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (1.2.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (0.28.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.3)\nRequirement already satisfied: shellingham in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (1.5.4)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (0.20.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert)\n  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.5.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->keybert) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->keybert) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->keybert) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->keybert) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.5->keybert) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.5->keybert) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2025.10.5)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (0.16.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (1.3.1)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (8.3.0)\nUsing cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\nUsing cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\nUsing cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\nInstalling collected packages: huggingface-hub, tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchtune 0.6.1 requires datasets, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.36.0 tokenizers-0.22.1 transformers-4.57.3\nCollecting transformers==4.44.2\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting evaluate==0.4.2\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting datasets==3.0.2\n  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: ipywidgets==8.1.1 in /usr/local/lib/python3.11/dist-packages (8.1.1)\nRequirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nCollecting gradio\n  Downloading gradio-6.0.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: huggingface_hub>=0.33.5 in /usr/local/lib/python3.11/dist-packages (0.36.0)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (4.15.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.20.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.5)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (4.67.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.2) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.2) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.2) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate==0.4.2) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.2) (2024.9.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.2) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.0.2) (3.13.2)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.1) (0.2.3)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.1) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.1) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.1) (4.0.15)\nRequirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.11/dist-packages (from ipywidgets==8.1.1) (3.0.15)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.3.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.11.0)\nRequirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\nRequirement already satisfied: gradio-client==2.0.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.0)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.3)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\nRequirement already satisfied: pydantic<=2.12.4,>=2.11.10 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.12.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.7)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.33.5) (1.2.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.2) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.2) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.2) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.2) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.2) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.2) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.0.2) (1.22.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (3.0.51)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (4.9.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.2) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate==0.4.2) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.12.4,>=2.11.10->gradio) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.5.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.1) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.1) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.1.1) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.2) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.44.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m284.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading datasets-3.0.2-py3-none-any.whl (472 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m233.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gradio-6.0.1-py3-none-any.whl (21.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m177.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m181.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers, datasets, gradio, evaluate\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.22.1\n    Uninstalling tokenizers-0.22.1:\n      Successfully uninstalled tokenizers-0.22.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.3\n    Uninstalling transformers-4.57.3:\n      Successfully uninstalled transformers-4.57.3\nSuccessfully installed datasets-3.0.2 evaluate-0.4.2 gradio-6.0.1 tokenizers-0.19.1 transformers-4.44.2\n--- Instalasi Selesai ---\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# SEL 2: Import Basic Libraries & List Files\n\nimport numpy as np\nimport pandas as pd\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(\"\\nâœ… Basic libraries imported successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:03:09.200828Z","iopub.execute_input":"2025-11-27T00:03:09.201070Z","iopub.status.idle":"2025-11-27T00:03:09.519247Z","shell.execute_reply.started":"2025-11-27T00:03:09.201048Z","shell.execute_reply":"2025-11-27T00:03:09.518606Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/asap-aes/valid_sample_submission_1_column.csv\n/kaggle/input/asap-aes/Training_Materials.zip\n/kaggle/input/asap-aes/training_set_rel3.xls\n/kaggle/input/asap-aes/valid_sample_submission_1_column_no_header.csv\n/kaggle/input/asap-aes/Essay_Set_Descriptions.zip\n/kaggle/input/asap-aes/training_set_rel3.xlsx\n/kaggle/input/asap-aes/valid_set.xls\n/kaggle/input/asap-aes/training_set_rel3.tsv\n/kaggle/input/asap-aes/valid_sample_submission_5_column.csv\n/kaggle/input/asap-aes/valid_set.xlsx\n/kaggle/input/asap-aes/valid_set.tsv\n/kaggle/input/asap-aes/test_set.tsv\n/kaggle/input/asap-aes/valid_sample_submission_2_column.csv\n\nâœ… Basic libraries imported successfully!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# SEL 3: Configuration\n\n\nimport torch\n\nconfigs = {\n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu'),\n    \"data_path\": \"/kaggle/input/asap-aes/training_set_rel3.tsv\",\n    \"eval_path\": \"/kaggle/input/asap-aes/test_set.tsv\",\n    \"save_path\": \"models\",\n    \"tokenizer_name\": \"bert-base-uncased\",\n    \"model_name\": \"bert-base-uncased\",\n    \"MAX_LENGTH\": 2048,\n    \"BATCH_SIZE\": 4,\n    \"EPOCHS\": 4,\n    \"patience\": 2,\n    \"learning_rate\": 2e-4,\n    \"weight_decay\": 0.01\n}\n\nprint(f\"ğŸ–¥ï¸ Device: {configs['device']}\")\nprint(\"âœ… Configuration loaded!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:03:09.519962Z","iopub.execute_input":"2025-11-27T00:03:09.520231Z","iopub.status.idle":"2025-11-27T00:03:11.216194Z","shell.execute_reply.started":"2025-11-27T00:03:09.520214Z","shell.execute_reply":"2025-11-27T00:03:11.215409Z"}},"outputs":[{"name":"stdout","text":"ğŸ–¥ï¸ Device: cuda\nâœ… Configuration loaded!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# SEL 4: Load & Split Data\n\nfrom sklearn.model_selection import train_test_split\n\nprint(\"ğŸ“‚ Loading dataset...\")\ntraining_data1 = pd.read_csv(\n    \"/kaggle/input/asap-aes/training_set_rel3.tsv\",\n    sep='\\t', \n    encoding='ISO-8859-1',\n    usecols=['essay_id', 'essay_set', 'essay', 'domain1_score']\n).dropna(axis=1)\n\nprint(f\"âœ… Dataset loaded: {training_data1.shape}\")\nprint(f\"Columns: {training_data1.columns.tolist()}\")\n\ntraining_data, test_data = train_test_split(\n    training_data1, \n    test_size=0.2, \n    random_state=42\n)\n\nprint(f\"ğŸ“Š Train set: {training_data.shape}\")\nprint(f\"ğŸ“Š Test set: {test_data.shape}\")\nprint(\"\\nSample data:\")\nprint(training_data.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:03:11.216960Z","iopub.execute_input":"2025-11-27T00:03:11.217327Z","iopub.status.idle":"2025-11-27T00:03:11.856058Z","shell.execute_reply.started":"2025-11-27T00:03:11.217297Z","shell.execute_reply":"2025-11-27T00:03:11.855404Z"}},"outputs":[{"name":"stdout","text":"ğŸ“‚ Loading dataset...\nâœ… Dataset loaded: (12976, 4)\nColumns: ['essay_id', 'essay_set', 'essay', 'domain1_score']\nğŸ“Š Train set: (10380, 4)\nğŸ“Š Test set: (2596, 4)\n\nSample data:\n      essay_id  essay_set                                              essay  \\\n2372      3567          2  There are many types of reading materials for ...   \n3038      4233          2  All terms of offense are based on an opinion. ...   \n4122      6518          3  The features of the setting affected the cycal...   \n\n      domain1_score  \n2372              4  \n3038              3  \n4122              1  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#  SEL 5: Import All ML/DL Libraries\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n\nimport time\nfrom tqdm import tqdm\n\nprint(\"âœ… All ML/DL libraries imported!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:03:11.857824Z","iopub.execute_input":"2025-11-27T00:03:11.858124Z","iopub.status.idle":"2025-11-27T00:03:12.322954Z","shell.execute_reply.started":"2025-11-27T00:03:11.858104Z","shell.execute_reply":"2025-11-27T00:03:12.322140Z"}},"outputs":[{"name":"stdout","text":"âœ… All ML/DL libraries imported!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#  SEL 6: Load SBERT Model\n\nfrom sentence_transformers import SentenceTransformer\nfrom keybert import KeyBERT\n\n\nprint(\"ğŸ”„ Loading SBERT model...\")\nsbert_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\nprint(\"âœ… SBERT model loaded: paraphrase-MiniLM-L6-v2\")\nkw_model = KeyBERT(model=sbert_model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:03:12.323764Z","iopub.execute_input":"2025-11-27T00:03:12.324058Z","iopub.status.idle":"2025-11-27T00:03:41.555134Z","shell.execute_reply.started":"2025-11-27T00:03:12.324035Z","shell.execute_reply":"2025-11-27T00:03:41.554471Z"}},"outputs":[{"name":"stderr","text":"2025-11-27 00:03:15.837428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764201796.030630     147 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764201796.086155     147 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"ğŸ”„ Loading SBERT model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61338adccd2446119da0539e672e3760"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19a33e55fd4848059ccb4315e10b8244"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"392167d80abd4e2b922a159aa0199e38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb4458d137494d3d943947d3cf200774"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be064ae13e3f4c758e583f55d8b542e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2faa9486acd4be58ec2222027195ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a5699107b7744a5874ea792b06d7515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5671e3dae9244097974bdc0ea17388d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e63d47b32ef4d138bbfdbe1268b6cb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ac3359696d2489095b93c73b1bdf6df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7598bbee1ad040c187aa4dc06b6d76c7"}},"metadata":{}},{"name":"stdout","text":"âœ… SBERT model loaded: paraphrase-MiniLM-L6-v2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#  SEL 7: Keyword Summarization Preprocessing \n\nfrom keybert import KeyBERT\n\nprint(\"ğŸ”„ Initializing KeyBERT using SBERT embeddings...\")\nkw_model = KeyBERT(model=sbert_model)\nprint(\"âœ… KeyBERT Ready!\")\n\n\ndef keyword_summarize(text, top_k=5):\n    \"\"\"\n    Ambil keyword dari teks â€” kompatibel dengan semua versi KeyBERT.\n    \"\"\"\n    keywords = kw_model.extract_keywords(\n        text,\n        keyphrase_ngram_range=(1, 2),\n        stop_words='english'\n    )\n    \n    keywords = keywords[:top_k]\n\n    key_list = [kw for kw, score in keywords]\n\n    return \" \".join(key_list) if key_list else text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:03:41.555887Z","iopub.execute_input":"2025-11-27T00:03:41.556507Z","iopub.status.idle":"2025-11-27T00:03:41.562314Z","shell.execute_reply.started":"2025-11-27T00:03:41.556485Z","shell.execute_reply":"2025-11-27T00:03:41.561612Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Initializing KeyBERT using SBERT embeddings...\nâœ… KeyBERT Ready!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#  SEL 8: COMPLETE TRAINING & COMPARISON\n\nprint(\"=\"*80)\nprint(\"ğŸš€ STARTING COMPLETE MODEL TRAINING & COMPARISON\")\nprint(\"=\"*80)\n\n#  HELPER FUNCTIONS\n\ndef qwk_score(y_true, y_pred, weights='quadratic'):\n    \"\"\"Calculate Quadratic Weighted Kappa (QWK).\"\"\"\n    y_pred_int = np.rint(y_pred).astype(int)\n    \n    if len(y_true) > 0:\n        min_score = min(y_true)\n        max_score = max(y_true)\n        y_pred_int = np.clip(y_pred_int, min_score, max_score)\n        return cohen_kappa_score(y_true, y_pred_int, weights=weights)\n    return 0.0\n\ndef get_sentence_embeddings(essay_text, show_progress_bar=False):\n    \"\"\"Get sentence embeddings from essay.\"\"\"\n    sentences = essay_text.split('. ')\n    sentence_embeddings = sbert_model.encode(\n        sentences, \n        convert_to_tensor=True, \n        show_progress_bar=show_progress_bar\n    )\n    return sentence_embeddings\n\ndef calculate_all_metrics(y_true, y_pred):\n    \"\"\"Calculate all evaluation metrics.\"\"\"\n    from sklearn.metrics import r2_score, mean_absolute_error\n    \n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_true, y_pred)\n    r2 = r2_score(y_true, y_pred)\n    qwk = qwk_score(y_true, y_pred)\n    \n    return {\n        'MSE': round(mse, 4),\n        'R2': round(r2, 4),\n        'MAE': round(mae, 4),\n        'RMSE': round(rmse, 4),\n        'QWK': round(qwk, 4)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:03:41.563199Z","iopub.execute_input":"2025-11-27T00:03:41.563496Z","iopub.status.idle":"2025-11-27T00:03:41.748627Z","shell.execute_reply.started":"2025-11-27T00:03:41.563471Z","shell.execute_reply":"2025-11-27T00:03:41.747860Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nğŸš€ STARTING COMPLETE MODEL TRAINING & COMPARISON\n================================================================================\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# sel 9 PREPARE DATA (WITH KEYWORD SUMMARIZATION)\n\nfrom keybert import KeyBERT\n\nprint(\"\\n[STEP 1] Preparing data...\")\n\nkw_model = KeyBERT(model=sbert_model)   \n\ndef keyword_summarize(text, top_k=5):\n    \"\"\"\n    Mengambil keyword penting dari teks dan mengembalikan\n    ringkasan singkat untuk membantu model memahami konteks.\n    \"\"\"\n    keywords = kw_model.extract_keywords(\n        text,\n        keyphrase_ngram_range=(1, 2),\n        stop_words='english'\n        \n    )\n    \n    keywords_filtered = keywords[:top_k] \n\n    key_list = [kw for kw, score in keywords_filtered]\n    \n    if len(key_list) == 0:\n        return text\n    \n    return \" \".join(key_list)\n\n\nprint(\"Applying keyword summarization...\")\nessays_raw = training_data['essay'].tolist()\nscores = training_data['domain1_score'].tolist()\n\nessays = []\nfor t in tqdm(essays_raw, desc=\"Summarizing essays\"):\n    essays.append(keyword_summarize(t, top_k=5))\n\n\n# Create embeddings using SBERT\n\nprint(\"Creating sentence embeddings...\")\nessay_embeddings = []\nfor essay in tqdm(essays, desc=\"Processing embeddings\"):\n    emb = get_sentence_embeddings(essay, show_progress_bar=False)\n    essay_embeddings.append(emb)\n\npadded_embeddings = nn.utils.rnn.pad_sequence(essay_embeddings, batch_first=True)\nessay_scores = torch.tensor(scores, dtype=torch.float32).view(-1, 1)\n\nprint(f\"âœ… Embeddings shape: {padded_embeddings.shape}\")\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    padded_embeddings, \n    essay_scores, \n    test_size=0.2, \n    random_state=42\n)\n\nprint(f\"Train: {X_train.shape}, Val: {X_val.shape}\")\n\n# Prepare for ML models (flatten)\nX_train_np = X_train.cpu().numpy()\ny_train_np = y_train.cpu().numpy().flatten()\n\n# Mean pooling\nmask = X_train_np != 0\ncount = np.sum(mask, axis=1)\ncount[count == 0] = 1\nX_train_sum = np.sum(X_train_np, axis=1)\nX_train_flat = X_train_sum / count\n\nprint(f\"Flat features shape: {X_train_flat.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:03:41.749450Z","iopub.execute_input":"2025-11-27T00:03:41.749777Z","iopub.status.idle":"2025-11-27T00:12:22.111437Z","shell.execute_reply.started":"2025-11-27T00:03:41.749760Z","shell.execute_reply":"2025-11-27T00:12:22.110547Z"}},"outputs":[{"name":"stdout","text":"\n[STEP 1] Preparing data...\nApplying keyword summarization...\n","output_type":"stream"},{"name":"stderr","text":"Summarizing essays: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10380/10380 [07:41<00:00, 22.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Creating sentence embeddings...\n","output_type":"stream"},{"name":"stderr","text":"Processing embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10380/10380 [00:58<00:00, 177.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… Embeddings shape: torch.Size([10380, 1, 384])\nTrain: torch.Size([8304, 1, 384]), Val: torch.Size([2076, 1, 384])\nFlat features shape: (8304, 384)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# sel 10 DEFINE DEEP LEARNING ARCHITECTURES\n\nEMBEDDING_DIM = X_train.shape[2]\nHIDDEN_DIM = 128\nOUTPUT_DIM = 1\nNUM_EPOCHS = 10\nDL_BATCH_SIZE = 64\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"\\n[STEP 2] Using device: {device}\")\n\n# LSTM Model\nclass LSTMModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(LSTMModel, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n    \n    def forward(self, x):\n        _, (hidden, _) = self.lstm(x)\n        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n        return self.fc(hidden)\n\n# CNN Model\nclass CNNModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n        self.pool = nn.AdaptiveMaxPool1d(1)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        x = x.permute(0, 2, 1)\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.pool(x).squeeze(2)\n        return self.fc(x)\n\n# LSTM-Attention Model\nclass LSTMAttentionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(LSTMAttentionModel, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.attention_weights = nn.Linear(hidden_dim * 2, 1)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n\n    def forward(self, x):\n        outputs, _ = self.lstm(x)\n        attn_scores = self.attention_weights(outputs)\n        attn_scores = torch.tanh(attn_scores)\n        attn_weights = torch.softmax(attn_scores, dim=1)\n        context = torch.sum(attn_weights * outputs, dim=1)\n        return self.fc(context)\n\nprint(\"âœ… Deep Learning architectures defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:12:22.112461Z","iopub.execute_input":"2025-11-27T00:12:22.112837Z","iopub.status.idle":"2025-11-27T00:12:22.123845Z","shell.execute_reply.started":"2025-11-27T00:12:22.112809Z","shell.execute_reply":"2025-11-27T00:12:22.123048Z"}},"outputs":[{"name":"stdout","text":"\n[STEP 2] Using device: cuda\nâœ… Deep Learning architectures defined!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ssel 11 TRAINING FUNCTION FOR DL MODELS\n\ndef train_dl_model(model, X_train_dl, y_train_dl, num_epochs=NUM_EPOCHS):\n    model.to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    \n    dataset = torch.utils.data.TensorDataset(\n        X_train_dl.to(device), \n        y_train_dl.to(device)\n    )\n    dataloader = torch.utils.data.DataLoader(\n        dataset, \n        batch_size=DL_BATCH_SIZE, \n        shuffle=True\n    )\n    \n    start_time = time.time()\n    \n    for epoch in tqdm(range(num_epochs), desc=f\"Training {model.__class__.__name__}\"):\n        model.train()\n        for X_batch, y_batch in dataloader:\n            optimizer.zero_grad()\n            y_pred = model(X_batch)\n            loss = criterion(y_pred, y_batch)\n            loss.backward()\n            optimizer.step()\n    \n    # Evaluate\n    model.eval()\n    with torch.no_grad():\n        y_pred_dl = model(X_train_dl.to(device)).cpu().numpy().flatten()\n    \n    # Calculate all metrics\n    metrics = calculate_all_metrics(y_train_np, y_pred_dl)\n    metrics['Waktu Pelatihan (s)'] = round(time.time() - start_time, 2)\n    \n    return metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:12:22.124496Z","iopub.execute_input":"2025-11-27T00:12:22.124832Z","iopub.status.idle":"2025-11-27T00:12:22.145836Z","shell.execute_reply.started":"2025-11-27T00:12:22.124808Z","shell.execute_reply":"2025-11-27T00:12:22.145163Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":" #12 TRAIN ALL MODELS\n\nprint(\"\\n[STEP 3] Training all models...\")\n\n# Deep Learning Models\ndl_models = {\n    \"LSTM\": LSTMModel(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM),\n    \"CNN\": CNNModel(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM),\n    \"LSTM-Attention\": LSTMAttentionModel(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n}\n\ndl_results = []\nfor name, model in dl_models.items():\n    print(f\"\\nğŸ”¥ Training: {name}\")\n    metrics = train_dl_model(model, X_train, y_train, NUM_EPOCHS)\n    metrics['Model'] = name\n    dl_results.append(metrics)\n    print(f\"  âœ… MSE: {metrics['MSE']} | RÂ²: {metrics['R2']} | MAE: {metrics['MAE']} | RMSE: {metrics['RMSE']} | QWK: {metrics['QWK']}\")\n\n# Machine Learning Models\nml_models = {\n    \"Random Forest\": RandomForestRegressor(random_state=42, n_estimators=100),\n    \"Support Vector Machines (SVR)\": SVR(kernel='rbf'),\n    \"k-Nearest Neighbor (KNN)\": KNeighborsRegressor(n_neighbors=5),\n    \"eXtreme Gradient Boosting (XGBoost)\": XGBRegressor(random_state=42, n_estimators=100)\n}\n\nml_results = []\nfor name, model in ml_models.items():\n    print(f\"\\nğŸ”¥ Training: {name}\")\n    start_time = time.time()\n    \n    model.fit(X_train_flat, y_train_np)\n    y_pred_ml = model.predict(X_train_flat)\n    \n    # Calculate all metrics\n    metrics = calculate_all_metrics(y_train_np, y_pred_ml)\n    metrics['Model'] = name\n    metrics['Waktu Pelatihan (s)'] = round(time.time() - start_time, 2)\n    \n    ml_results.append(metrics)\n    print(f\"  âœ… MSE: {metrics['MSE']} | RÂ²: {metrics['R2']} | MAE: {metrics['MAE']} | RMSE: {metrics['RMSE']} | QWK: {metrics['QWK']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:12:22.146443Z","iopub.execute_input":"2025-11-27T00:12:22.146678Z","iopub.status.idle":"2025-11-27T00:21:32.226762Z","shell.execute_reply.started":"2025-11-27T00:12:22.146663Z","shell.execute_reply":"2025-11-27T00:21:32.225992Z"}},"outputs":[{"name":"stdout","text":"\n[STEP 3] Training all models...\n\nğŸ”¥ Training: LSTM\n","output_type":"stream"},{"name":"stderr","text":"Training LSTMModel: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:03<00:00,  2.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"  âœ… MSE: 7.403500080108643 | RÂ²: 0.9082 | MAE: 1.513800024986267 | RMSE: 2.720900058746338 | QWK: 0.951\n\nğŸ”¥ Training: CNN\n","output_type":"stream"},{"name":"stderr","text":"Training CNNModel: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  3.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"  âœ… MSE: 12.593299865722656 | RÂ²: 0.8439 | MAE: 1.9668999910354614 | RMSE: 3.5487000942230225 | QWK: 0.916\n\nğŸ”¥ Training: LSTM-Attention\n","output_type":"stream"},{"name":"stderr","text":"Training LSTMAttentionModel: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:04<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"  âœ… MSE: 7.310299873352051 | RÂ²: 0.9094 | MAE: 1.5348000526428223 | RMSE: 2.7037999629974365 | QWK: 0.9528\n\nğŸ”¥ Training: Random Forest\n  âœ… MSE: 3.2485 | RÂ²: 0.9597 | MAE: 0.916 | RMSE: 1.8024 | QWK: 0.9773\n\nğŸ”¥ Training: Support Vector Machines (SVR)\n  âœ… MSE: 23.4018 | RÂ²: 0.7099 | MAE: 2.0902 | RMSE: 4.8375 | QWK: 0.8125\n\nğŸ”¥ Training: k-Nearest Neighbor (KNN)\n  âœ… MSE: 11.851200103759766 | RÂ²: 0.8531 | MAE: 1.5812000036239624 | RMSE: 3.4426000118255615 | QWK: 0.9184\n\nğŸ”¥ Training: eXtreme Gradient Boosting (XGBoost)\n  âœ… MSE: 0.38199999928474426 | RÂ²: 0.9953 | MAE: 0.47929999232292175 | RMSE: 0.6179999709129333 | QWK: 0.9971\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"#13 FINAL COMPARISON TABLE\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ğŸ† FINAL RESULTS COMPARISON\")\nprint(\"=\"*80)\n\ndf_comparison = pd.DataFrame(dl_results + ml_results)\n\n# Reorder columns to match your format\ndf_comparison = df_comparison[['Model', 'MSE', 'R2', 'MAE', 'RMSE', 'QWK', 'Waktu Pelatihan (s)']]\n\n# Sort by QWK (highest is best)\ndf_comparison = df_comparison.sort_values(by=\"QWK\", ascending=False)\n\nprint(\"\\n\" + df_comparison.to_markdown(index=False))\nprint(\"=\"*80)\n\n# Best model\nbest_model_name = df_comparison.iloc[0][\"Model\"]\nbest_qwk = df_comparison.iloc[0][\"QWK\"]\nbest_r2 = df_comparison.iloc[0][\"R2\"]\nbest_rmse = df_comparison.iloc[0][\"RMSE\"]\n\nprint(f\"\\nğŸ† BEST MODEL: {best_model_name}\")\nprint(f\"   - QWK: {best_qwk}\")\nprint(f\"   - RÂ²: {best_r2}\")\nprint(f\"   - RMSE: {best_rmse}\")\nprint(\"\\nâœ… TRAINING COMPLETED!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:21:32.227631Z","iopub.execute_input":"2025-11-27T00:21:32.227866Z","iopub.status.idle":"2025-11-27T00:21:32.266958Z","shell.execute_reply.started":"2025-11-27T00:21:32.227847Z","shell.execute_reply":"2025-11-27T00:21:32.266389Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nğŸ† FINAL RESULTS COMPARISON\n================================================================================\n\n| Model                               |     MSE |     R2 |    MAE |   RMSE |    QWK |   Waktu Pelatihan (s) |\n|:------------------------------------|--------:|-------:|-------:|-------:|-------:|----------------------:|\n| eXtreme Gradient Boosting (XGBoost) |  0.382  | 0.9953 | 0.4793 | 0.618  | 0.9971 |                  6.8  |\n| Random Forest                       |  3.2485 | 0.9597 | 0.916  | 1.8024 | 0.9773 |                497.89 |\n| LSTM-Attention                      |  7.3103 | 0.9094 | 1.5348 | 2.7038 | 0.9528 |                  4.39 |\n| LSTM                                |  7.4035 | 0.9082 | 1.5138 | 2.7209 | 0.951  |                  4.05 |\n| k-Nearest Neighbor (KNN)            | 11.8512 | 0.8531 | 1.5812 | 3.4426 | 0.9184 |                  0.77 |\n| CNN                                 | 12.5933 | 0.8439 | 1.9669 | 3.5487 | 0.916  |                  2.75 |\n| Support Vector Machines (SVR)       | 23.4018 | 0.7099 | 2.0902 | 4.8375 | 0.8125 |                 33.36 |\n================================================================================\n\nğŸ† BEST MODEL: eXtreme Gradient Boosting (XGBoost)\n   - QWK: 0.9971\n   - RÂ²: 0.9953\n   - RMSE: 0.6179999709129333\n\nâœ… TRAINING COMPLETED!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# 14 SAVE ALL MODELS\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ğŸ’¾ SAVING MODELS\")\nprint(\"=\"*80)\n\nimport os\nos.makedirs('models', exist_ok=True)\n\n# Save Deep Learning models (.pth)\nprint(\"\\nğŸ“¦ Saving Deep Learning models (.pth)...\")\nfor name, model in dl_models.items():\n    model_path = f\"models/{name.replace(' ', '_')}.pth\"\n    \n    # Save model state dict + architecture info\n    torch.save({\n        'model_name': name,\n        'model_state_dict': model.state_dict(),\n        'embedding_dim': EMBEDDING_DIM,\n        'hidden_dim': HIDDEN_DIM,\n        'output_dim': OUTPUT_DIM,\n        'metrics': next((item for item in dl_results if item['Model'] == name), None)\n    }, model_path)\n    \n    print(f\"  âœ… Saved: {model_path}\")\n\n# Save Machine Learning models (.pkl)\nprint(\"\\nğŸ“¦ Saving Machine Learning models (.pkl)...\")\nimport pickle\n\nfor name, model in ml_models.items():\n    model_path = f\"models/{name.replace(' ', '_')}.pkl\"\n    \n    with open(model_path, 'wb') as f:\n        pickle.dump({\n            'model_name': name,\n            'model': model,\n            'metrics': next((item for item in ml_results if item['Model'] == name), None)\n        }, f)\n    \n    print(f\"  âœ… Saved: {model_path}\")\n\n# Save best model specifically\nprint(\"\\nğŸ† Saving best model...\")\nif best_model_name in dl_models:\n    # Deep Learning model\n    best_model_path = f\"models/BEST_MODEL_{best_model_name.replace(' ', '_')}.pth\"\n    torch.save({\n        'model_name': best_model_name,\n        'model_state_dict': dl_models[best_model_name].state_dict(),\n        'embedding_dim': EMBEDDING_DIM,\n        'hidden_dim': HIDDEN_DIM,\n        'output_dim': OUTPUT_DIM,\n        'metrics': df_comparison.iloc[0].to_dict(),\n        'model_type': 'deep_learning'\n    }, best_model_path)\nelse:\n    # Machine Learning model\n    best_model_path = f\"models/BEST_MODEL_{best_model_name.replace(' ', '_')}.pkl\"\n    with open(best_model_path, 'wb') as f:\n        pickle.dump({\n            'model_name': best_model_name,\n            'model': ml_models[best_model_name],\n            'metrics': df_comparison.iloc[0].to_dict(),\n            'model_type': 'machine_learning'\n        }, f)\n\nprint(f\"  âœ… Saved best model: {best_model_path}\")\n\n# Save comparison results\ndf_comparison.to_csv('models/comparison_results.csv', index=False)\nprint(f\"  âœ… Saved comparison table: models/comparison_results.csv\")\n\n# Save metadata\nmetadata = {\n    'best_model': best_model_name,\n    'best_qwk': best_qwk,\n    'best_r2': best_r2,\n    'best_rmse': best_rmse,\n    'embedding_dim': EMBEDDING_DIM,\n    'hidden_dim': HIDDEN_DIM,\n    'num_epochs': NUM_EPOCHS,\n    'batch_size': DL_BATCH_SIZE,\n    'sbert_model': 'paraphrase-MiniLM-L6-v2'\n}\n\nwith open('models/metadata.pkl', 'wb') as f:\n    pickle.dump(metadata, f)\n\nprint(f\"  âœ… Saved metadata: models/metadata.pkl\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"âœ… ALL MODELS SAVED SUCCESSFULLY!\")\nprint(\"=\"*80)\nprint(\"\\nğŸ“ Saved files:\")\nprint(\"  - models/*.pth (Deep Learning models)\")\nprint(\"  - models/*.pkl (Machine Learning models)\")\nprint(\"  - models/BEST_MODEL_*.pth or .pkl\")\nprint(\"  - models/comparison_results.csv\")\nprint(\"  - models/metadata.pkl\")\n\nprint(\"\\nâœ… TRAINING COMPLETED!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:21:32.268929Z","iopub.execute_input":"2025-11-27T00:21:32.269300Z","iopub.status.idle":"2025-11-27T00:21:32.357511Z","shell.execute_reply.started":"2025-11-27T00:21:32.269282Z","shell.execute_reply":"2025-11-27T00:21:32.356635Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nğŸ’¾ SAVING MODELS\n================================================================================\n\nğŸ“¦ Saving Deep Learning models (.pth)...\n  âœ… Saved: models/LSTM.pth\n  âœ… Saved: models/CNN.pth\n  âœ… Saved: models/LSTM-Attention.pth\n\nğŸ“¦ Saving Machine Learning models (.pkl)...\n  âœ… Saved: models/Random_Forest.pkl\n  âœ… Saved: models/Support_Vector_Machines_(SVR).pkl\n  âœ… Saved: models/k-Nearest_Neighbor_(KNN).pkl\n  âœ… Saved: models/eXtreme_Gradient_Boosting_(XGBoost).pkl\n\nğŸ† Saving best model...\n  âœ… Saved best model: models/BEST_MODEL_eXtreme_Gradient_Boosting_(XGBoost).pkl\n  âœ… Saved comparison table: models/comparison_results.csv\n  âœ… Saved metadata: models/metadata.pkl\n\n================================================================================\nâœ… ALL MODELS SAVED SUCCESSFULLY!\n================================================================================\n\nğŸ“ Saved files:\n  - models/*.pth (Deep Learning models)\n  - models/*.pkl (Machine Learning models)\n  - models/BEST_MODEL_*.pth or .pkl\n  - models/comparison_results.csv\n  - models/metadata.pkl\n\nâœ… TRAINING COMPLETED!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# =======================================================\n# ğŸ¯ HYBRID AI GRADING SYSTEM (OPENROUTER FIXED - CLEAN)\n# =======================================================\n\nimport gradio as gr\nimport joblib\nimport pandas as pd # Tambahan impor\nimport numpy as np # Tambahan impor\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport openai \nimport json\nimport os # Tambahan impor\nimport torch # Tambahan impor\nimport torch.nn as nn # Tambahan impor\nfrom sentence_transformers import SentenceTransformer # Tambahan impor\nfrom xgboost import XGBRegressor # Tambahan impor\n\nprint(\"=\"*60)\nprint(\"ğŸš€ INITIALIZING HYBRID AI GRADING SYSTEM (OpenRouter Mode)\")\nprint(\"=\"*60)\n\n# =====================================================\n# ğŸ”§ 1. LOAD SBERT MODEL\n# =====================================================\n\nprint(\"\\nğŸ”„ Loading SBERT model...\")\ntry:\n    # Muat model SBERT\n    encoder = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n    print(\"âœ… SBERT model loaded successfully!\")\nexcept Exception as e:\n    print(f\"âŒ Error loading SBERT: {e}\")\n    encoder = None\n\n# =====================================================\n# ğŸ”§ 2. PLACEHOLDER DL MODEL CLASS\n# =====================================================\n\nclass MyModel(torch.nn.Module):\n    def __init__(self, input_dim=384, hidden_dim=128, output_dim=1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        return self.fc2(x)\n\n# =====================================================\n# ğŸ”§ 3. LOAD TRAINED MODEL (ML/DL)\n# =====================================================\n\ndef get_dummy_model():\n    \"\"\"Fallback jika model tidak ditemukan\"\"\"\n    print(\"âš ï¸ Model asli tidak ditemukan, menggunakan DUMMY Model\")\n    dummy = XGBRegressor(random_state=42)\n    # Fit dengan data random agar bisa .predict()\n    dummy.fit(np.random.rand(10, 384), np.random.rand(10) * 12)\n    return dummy, \"ml\", 12.0 # Max score dataset ASAP-AES\n\ndef load_custom_model():\n    model_dir = \"models\"\n    \n    if not os.path.exists(model_dir):\n        os.makedirs(model_dir, exist_ok=True)\n        return get_dummy_model()\n    \n    try:\n        files = os.listdir(model_dir)\n        \n        best_pkl = next((os.path.join(model_dir, f) for f in files if \"BEST_MODEL\" in f and f.endswith(\".pkl\")), None)\n        best_pth = next((os.path.join(model_dir, f) for f in files if \"BEST_MODEL\" in f and f.endswith(\".pth\")), None)\n        \n        if best_pkl:\n            print(f\"ğŸš€ Loading ML Model: {best_pkl}\")\n            data = joblib.load(best_pkl)\n            model = data.get('model', data.get('estimator', data)) if isinstance(data, dict) else data\n            if model is None:\n                 print(\"âŒ Model tidak ditemukan dalam dict\")\n                 return get_dummy_model()\n            print(\"âœ… ML Model loaded successfully!\")\n            return model, \"ml\", 12.0\n        \n        if best_pth:\n            print(f\"ğŸš€ Loading DL Model: {best_pth}\")\n            model = MyModel()\n            checkpoint = torch.load(best_pth, map_location=\"cpu\")\n            state_dict = checkpoint.get('model_state_dict', checkpoint) if isinstance(checkpoint, dict) else checkpoint\n            model.load_state_dict(state_dict)\n            model.eval()\n            print(\"âœ… DL Model loaded successfully!\")\n            return model, \"dl\", 12.0\n            \n        return get_dummy_model()\n        \n    except Exception as e:\n        print(f\"âŒ Error loading model: {e}\")\n        return get_dummy_model()\n\n# Load model global\nbest_model, model_type, model_max_score = load_custom_model()\nprint(f\"\\nğŸ“Š Model Type: {model_type.upper()}\")\nprint(f\"ğŸ“Š Max Score Range: 0-{model_max_score}\")\n\n# =====================================================\n# ğŸ§  4. OPENROUTER LLM CHECKER (via OpenAI standard)\n# =====================================================\n\ndef cek_konteks_llm(api_key, soal, kunci, jawaban_mhs):\n    if not api_key or not api_key.strip() or not jawaban_mhs.strip():\n        return 0, \"âš ï¸ API Key/Jawaban kosong. Mode Offline.\"\n    \n    try:\n        # Inisialisasi client OpenRouter (menggunakan format OpenAI)\n        client = openai.OpenAI(\n            base_url=\"https://openrouter.ai/api/v1\",\n            api_key=api_key,\n        )\n\n        OPENROUTER_MODEL = \"mistralai/mistral-7b-instruct:free\" \n        \n        prompt = f\"\"\"\nKamu adalah Dosen Penilai yang Objektif dan Teliti.\n\n**SOAL:**\n{soal}\n\n**KUNCI JAWABAN (Reference):**\n{kunci}\n\n**JAWABAN MAHASISWA:**\n{jawaban_mhs}\n\n**TUGAS:**\nBerikan penilaian objektif berdasarkan kriteria: Relevansi (40%), Kebenaran (40%), Kelengkapan (20%).\nHanya beri skor rendah jika benar-benar salah/tidak relevan.\n\n**OUTPUT (WAJIB FORMAT JSON):**\n{{\"skor\": <integer 0-100>, \"alasan\": \"<penjelasan singkat 1-2 kalimat>\"}}\n\"\"\"\n        \n        response = client.chat.completions.create(\n            model=OPENROUTER_MODEL,\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are an objective essay grader. Your output must be a single JSON object. Only output the JSON.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            response_format={\"type\": \"json_object\"}, \n            temperature=0.3\n        )\n        \n        text_res = response.choices[0].message.content.strip()\n        data = json.loads(text_res)\n        skor = max(0, min(100, int(data.get('skor', 0))))\n        alasan = data.get('alasan', 'Tidak ada feedback')\n        return skor, alasan\n        \n    except json.JSONDecodeError:\n        import re\n        match = re.search(r'\"skor\"\\s*:\\s*(\\d+)', text_res)\n        if match:\n            skor = max(0, min(100, int(match.group(1))))\n            return skor, \"Feedback parsing error, skor diekstrak manual\"\n        else:\n            return 0, f\"âš ï¸ Gagal parse response OpenRouter: {text_res[:100]}...\"\n            \n    except openai.APIError as e:\n        error_msg = str(e)\n        if \"rate limit\" in error_msg.lower() or \"429\" in error_msg:\n             return 0, \"âŒ OpenRouter Error: Quota/Rate Limit habis. Sistem fallback ke mode Offline.\"\n        elif \"authentication\" in error_msg.lower() or \"401\" in error_msg:\n             return 0, \"âŒ OpenRouter Error: API Key tidak valid.\"\n        print(f\"âŒ OpenRouter API Error: {error_msg}\")\n        return 0, f\"âŒ OpenRouter Error: {error_msg[:50]}... | Mode fallback aktif.\"\n\n    except Exception as e:\n        error_msg = str(e)\n        print(f\"âŒ Unexpected OpenRouter Error: {error_msg}\")\n        return 0, f\"âŒ Error tak terduga: {error_msg[:50]}... | Mode fallback aktif.\"\n\n\n# =====================================================\n# ğŸ¯ 5. HYBRID GRADING FUNCTION (CORE LOGIC)\n# =====================================================\n\ndef grade_essay_hybrid(api_key, jawaban_mahasiswa, current_state):\n    if not jawaban_mahasiswa or not jawaban_mahasiswa.strip():\n        return 0.0, 0.0, 0.0, \"Jawaban kosong\", \"N/A\"\n        \n    soal = current_state.get(\"soal\", \"\")\n    kunci_jawaban = current_state.get(\"jawaban_benar\", \"\")\n    max_score_dosen = current_state.get(\"max_score\", 100)\n    \n    # STEP 1: TECHNICAL SCORING (Model-based)\n    try:\n        emb_mhs = encoder.encode([jawaban_mahasiswa])\n        emb_kunci = encoder.encode([kunci_jawaban])\n        \n        similarity = cosine_similarity(emb_mhs, emb_kunci)[0][0]\n        similarity = max(0.0, similarity)\n        \n        if model_type == \"ml\":\n            raw_pred = best_model.predict(emb_mhs)[0]\n        else:\n            t_mhs = torch.tensor(emb_mhs, dtype=torch.float32)\n            with torch.no_grad():\n                raw_pred = best_model(t_mhs).item()\n        \n        score_technical = (float(raw_pred) / model_max_score) * 100\n        score_technical = max(0.0, min(100.0, score_technical))\n        if similarity > 0.99:\n            score_technical = 100.0\n    \n    except Exception as e:\n        print(f\"âŒ Technical scoring error: {e}\")\n        score_technical = 0.0\n        similarity = 0.0\n    \n    # STEP 2: LOGICAL SCORING (LLM-based)\n    score_llm, feedback_llm = cek_konteks_llm(api_key, soal, kunci_jawaban, jawaban_mahasiswa)\n    \n    # STEP 3: FINAL SCORE CALCULATION\n    llm_success = (score_llm > 0 or \"Error\" not in feedback_llm) and api_key and \"Offline\" not in feedback_llm\n    \n    if llm_success:\n        # HYBRID MODE (Online with LLM): 40% Technical + 60% LLM\n        final_score_raw = (score_technical * 0.4) + (score_llm * 0.6)\n        mode_used = \"ğŸŸ¢ Hybrid (AI+Model)\"\n    else:\n        # OFFLINE MODE (Fallback tanpa LLM): 50% Model + 50% Similarity\n        similarity_score = similarity * 100\n        final_score_raw = (score_technical * 0.5) + (similarity_score * 0.5)\n        mode_used = \"ğŸŸ¡ Offline (Model Only)\"\n    \n    # Scale ke max_score dosen\n    final_score = (final_score_raw / 100.0) * max_score_dosen\n    final_score = max(0.0, min(max_score_dosen, final_score))\n    \n    return (\n        round(final_score, 2),\n        round(score_technical, 2),\n        round(score_llm, 2),\n        feedback_llm,\n        mode_used\n    )\n\n# =====================================================\n# ğŸ—‚ï¸ 6. GRADIO UI LOGIC FUNCTIONS\n# =====================================================\n\ndef simpan_soal(soal, jawaban_benar, max_score, state):\n    \"\"\"Handler untuk tombol Simpan Soal\"\"\"\n    if not soal or not soal.strip() or not jawaban_benar or not jawaban_benar.strip():\n        empty_df = pd.DataFrame(columns=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\", \"Mode\", \"Feedback\"])\n        return state, \"âŒ Soal/Kunci Jawaban tidak boleh kosong!\", empty_df\n    \n    new_state = {\n        \"soal\": soal,\n        \"jawaban_benar\": jawaban_benar,\n        \"max_score\": float(max_score) if max_score else 100.0,\n        \"leaderboard\": pd.DataFrame(columns=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\", \"Mode\", \"Feedback\"])\n    }\n    \n    status_msg = f\"âœ… Soal tersimpan!\\nğŸ“ Soal: {soal[:50]}...\\nğŸ¯ Max Score: {new_state['max_score']}\"\n    \n    return new_state, status_msg, new_state[\"leaderboard\"]\n\n\ndef submit_jawaban_hybrid(api_key, nama, jawaban, state):\n    \"\"\"Handler untuk tombol Submit Jawaban\"\"\"\n    if not state or \"soal\" not in state or not state[\"soal\"]:\n        return state, state.get(\"leaderboard\", pd.DataFrame()), \"âš ï¸ **Error:** Dosen belum membuat soal!\"\n    \n    if not nama or not nama.strip():\n        return state, state.get(\"leaderboard\", pd.DataFrame()), \"âš ï¸ **Error:** Nama harus diisi!\"\n    \n    if not jawaban or not jawaban.strip():\n        return state, state.get(\"leaderboard\", pd.DataFrame()), \"âš ï¸ **Error:** Jawaban harus diisi!\"\n    \n    total, teknis, logika, feedback, mode = grade_essay_hybrid(api_key, jawaban, state)\n    \n    # Update leaderboard\n    df = state.get(\"leaderboard\", pd.DataFrame(columns=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\", \"Mode\", \"Feedback\"]))\n    \n    new_row = {\n        \"Nama\": nama, \"Total\": total, \"Teknis\": teknis, \n        \"Logika(AI)\": logika, \"Mode\": mode, \"Feedback\": feedback\n    }\n    \n    # Cek dan update/tambah row\n    if not df.empty and nama in df[\"Nama\"].values:\n        df.loc[df[\"Nama\"] == nama, list(new_row.keys())] = list(new_row.values())\n    else:\n        new_df = pd.DataFrame([new_row])\n        df = pd.concat([df, new_df], ignore_index=True)\n    \n    df = df.sort_values(by=\"Total\", ascending=False).reset_index(drop=True)\n    state[\"leaderboard\"] = df\n    \n    # Format feedback message\n    max_score = state.get(\"max_score\", 100)\n    emoji = \"ğŸ“š\"\n    grade = \"Perlu Belajar\"\n    if total >= max_score * 0.9:\n        emoji = \"ğŸŒŸ\"\n        grade = \"Sempurna!\"\n    elif total >= max_score * 0.7:\n        emoji = \"âœ…\"\n        grade = \"Bagus!\"\n    elif total >= max_score * 0.5:\n        emoji = \"ğŸ‘\"\n        grade = \"Cukup\"\n    \n    msg = f\"\"\"\n### {emoji} Hasil Penilaian: **{nama}**\n---\n**ğŸ† SKOR AKHIR: {total} / {max_score}** ({grade})\nğŸ“Š **Rincian Penilaian:**\n- ğŸ¤– **Teknis (Model):** {teknis}/100 \n- ğŸ§  **Logika (AI):** {logika}/100 \n---\nğŸ’¡ **Feedback AI:** > {feedback}\nğŸ”§ **Mode:** {mode}\n---\n\"\"\"\n    return state, df.drop(columns=[\"Feedback\"]), msg # Leaderboard di mhs tidak tampilkan kolom Feedback\n\n\ndef tampilkan_soal(state):\n    \"\"\"Tampilkan soal di tab mahasiswa\"\"\"\n    if state and \"soal\" in state and state[\"soal\"]:\n        return f\"ğŸ“‹ **Soal:**\\n\\n{state['soal']}\"\n    return \"âš ï¸ _(Dosen belum membuat soal)_\"\n\n# =====================================================\n# ğŸ¨ 7. GRADIO UI (COMPLETE & CLEAN)\n# =====================================================\n\nwith gr.Blocks(title=\"Hybrid AI Grader\") as demo:\n    initial_state = {\n        \"soal\": None, \"jawaban_benar\": None, \"max_score\": 100.0,\n        \"leaderboard\": pd.DataFrame(columns=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\", \"Mode\", \"Feedback\"])\n    }\n    state = gr.State(initial_state)\n    \n    gr.Markdown(\"\"\"\n    # ğŸš€ Hybrid AI Essay Grading System\n    ### Sistem Penilaian Esai dengan 3 Teknologi: ğŸ¤– SBERT + ğŸ“Š ML Model + ğŸ§  LLM (OpenRouter)\n    ---\n    \"\"\")\n    \n    # API Key Setup\n    with gr.Accordion(\"ğŸ”‘ Setup API Key OpenRouter (Required for Smart Mode)\", open=False):\n        gr.Markdown(\"\"\"\n        **Cara Mendapatkan API Key OpenRouter:** [OpenRouter Dashboard](https://openrouter.ai/keys)\n        âš ï¸ **Tanpa API Key:** Sistem akan berjalan dalam mode Offline (akurasi berkurang)\n        \"\"\")\n        api_key_input = gr.Textbox(\n            label=\"OpenRouter API Key\", type=\"password\", placeholder=\"sk-or-v1-...\", \n            info=\"Key ini menggantikan Gemini Key. TIDAK akan disimpan.\"\n        )\n    \n    with gr.Tabs():\n        # TAB 1: PORTAL DOSEN\n        with gr.Tab(\"ğŸ‘¨â€ğŸ« Portal Dosen\"):\n            gr.Markdown(\"### Buat Soal & Kunci Jawaban\")\n            \n            with gr.Row():\n                with gr.Column(scale=2):\n                    soal_in = gr.Textbox(label=\"ğŸ“ Soal Essay\", lines=3, placeholder=\"Jelaskan dampak AI pada pendidikan modern...\")\n                    kunci_in = gr.Textbox(label=\"âœ… Kunci Jawaban (Referensi Ideal)\", lines=8, placeholder=\"Tuliskan jawaban ideal...\")\n                \n                with gr.Column(scale=1):\n                    max_score = gr.Number(value=100, label=\"ğŸ¯ Skor Maksimal\")\n                    btn_save = gr.Button(\"ğŸ’¾ Simpan Soal\", variant=\"primary\", size=\"lg\")\n                    status_dosen = gr.Textbox(label=\"ğŸ“Š Status\", interactive=False, lines=3)\n            \n            gr.Markdown(\"---\")\n            gr.Markdown(\"### ğŸ“Š Preview Leaderboard (Dosen)\")\n            leaderboard_dosen = gr.DataFrame(label=\"Leaderboard (Live)\", interactive=False)\n            \n            # Connect button\n            btn_save.click(\n                fn=simpan_soal,\n                inputs=[soal_in, kunci_in, max_score, state],\n                outputs=[state, status_dosen, leaderboard_dosen]\n            )\n        \n        # TAB 2: PORTAL MAHASISWA\n        with gr.Tab(\"ğŸ§‘â€ğŸ“ Portal Mahasiswa\") as mahasiswa_tab:\n            gr.Markdown(\"### Lihat Soal & Submit Jawaban\")\n            \n            soal_display = gr.Markdown(value=\"âš ï¸ _(Dosen belum membuat soal)_\")\n            \n            with gr.Row():\n                with gr.Column(scale=2):\n                    nama_in = gr.Textbox(label=\"ğŸ‘¤ Nama Lengkap\", placeholder=\"Contoh: Budi Santoso\")\n                    jawab_in = gr.Textbox(label=\"âœï¸ Jawaban Kamu\", lines=10, placeholder=\"Tuliskan jawabanmu di sini...\")\n                    btn_submit = gr.Button(\"ğŸš€ Kirim Jawaban\", variant=\"primary\", size=\"lg\")\n                \n                with gr.Column(scale=1):\n                    gr.Markdown(\"### ğŸ† Live Leaderboard (Top 5)\")\n                    lb_mhs = gr.DataFrame(label=\"Top Scores\", interactive=False, headers=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\"])\n            \n            gr.Markdown(\"---\")\n            status_mhs = gr.Markdown(value=\"_Isi form di atas dan klik 'Kirim Jawaban'_\")\n            \n            # Connect button\n            btn_submit.click(\n                fn=submit_jawaban_hybrid,\n                inputs=[api_key_input, nama_in, jawab_in, state],\n                outputs=[state, lb_mhs, status_mhs]\n            )\n            \n            # Update soal saat tab dibuka\n            mahasiswa_tab.select(\n                fn=tampilkan_soal,\n                inputs=[state],\n                outputs=[soal_display]\n            )\n\n# =====================================================\n# ğŸš€ 8. LAUNCH APPLICATION\n# =====================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ… SYSTEM READY!\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š Model Type: {model_type.upper()}\")\nprint(f\"ğŸ¤– SBERT: {'âœ… Loaded' if encoder else 'âŒ Failed'}\")\nprint(f\"ğŸ§  LLM: OpenRouter (via Mistral 7B)\")\nprint(\"=\"*60)\nprint(\"\\nğŸš€ Launching Gradio interface...\\n\")\n\ndemo.launch(share=True, debug=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T00:21:32.358553Z","iopub.execute_input":"2025-11-27T00:21:32.358931Z","execution_failed":"2025-11-27T05:59:33.821Z"}},"outputs":[{"name":"stdout","text":"============================================================\nğŸš€ INITIALIZING HYBRID AI GRADING SYSTEM (OpenRouter Mode)\n============================================================\n\nğŸ”„ Loading SBERT model...\nâœ… SBERT model loaded successfully!\nğŸš€ Loading ML Model: models/BEST_MODEL_eXtreme_Gradient_Boosting_(XGBoost).pkl\nâœ… ML Model loaded successfully!\n\nğŸ“Š Model Type: ML\nğŸ“Š Max Score Range: 0-12.0\n\n============================================================\nâœ… SYSTEM READY!\n============================================================\nğŸ“Š Model Type: ML\nğŸ¤– SBERT: âœ… Loaded\nğŸ§  LLM: OpenRouter (via Mistral 7B)\n============================================================\n\nğŸš€ Launching Gradio interface...\n\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://15a35e07a5a0d248f0.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://15a35e07a5a0d248f0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":670001,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":507406,"modelId":522117}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================================================================\n# üéØ COMPREHENSIVE GRADING SYSTEM (UPDATED METRICS)\n# ================================================================\n# METRICS: MAE, MSE, RMSE, R2 Score, QWK (Quadratic Weighted Kappa)\n# FITUR: Auto-search path, Hybrid Scoring, LLM Integration\n# ================================================================\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n# --- TAMBAHAN IMPORT UNTUK METRICS ---\nfrom sklearn.metrics import mean_squared_error, r2_score, cohen_kappa_score, mean_absolute_error\nimport openai\nimport json\nimport joblib\nimport os\nfrom xgboost import XGBRegressor\n\nprint(\"=\"*80)\nprint(\"üéØ INITIALIZING COMPREHENSIVE GRADING COMPARISON SYSTEM\")\nprint(\"=\"*80)\n\n# =====================================================\n# üìä STEP 1: INPUT DATA (Manual Dictionary)\n# =====================================================\n\ndef input_manual():\n    return {\n        \"soal\": \"\"\"Write a response that explains how the features of the setting affect the cyclist. In your response, include examples from the essay that support your conclusion.\"\"\",\n        \n        \"kunci_jawaban\": \"\"\"ROUGH ROAD AHEAD: Do Not Exceed Posted Speed Limit by Joe Kurmaskie... (Truncated for brevity) ...And I promised myself right then that I'd always stick to it in the future.\"\"\",\n        \n        \"max_score\": 3,\n        \n        \"data_siswa\": [\n            {\"nama\": \"Siswa 1\", \"jawaban\": \"The features of the setting affect the cyclist in many ways...\", \"skor_asli\": 1},\n            {\"nama\": \"Siswa 2\", \"jawaban\": \"The features of the setting affected the cyclist in a negative way...\", \"skor_asli\": 2},\n            {\"nama\": \"Siswa 3\", \"jawaban\": \"Everyone travels to unfamiliar places...\", \"skor_asli\": 1},\n            {\"nama\": \"Siswa 4\", \"jawaban\": \"I believe the features of the cyclist affected him because he was impatient...\", \"skor_asli\": 1},\n            {\"nama\": \"Siswa 5\", \"jawaban\": \"The setting effects the cyclist because of the setting were diffrent...\", \"skor_asli\": 2},\n            {\"nama\": \"Siswa 6\", \"jawaban\": \"There were many features of the setting that affected the cyclist...\", \"skor_asli\": 1},\n            {\"nama\": \"Siswa 7\", \"jawaban\": \"The cyclist was riding through a tower when he stopped for directions...\", \"skor_asli\": 1},\n            {\"nama\": \"Siswa 8\", \"jawaban\": \"The affects of the cyclist is if it does not change...\", \"skor_asli\": 0},\n            {\"nama\": \"Siswa 9\", \"jawaban\": \"The essay 'Rough Road Ahead' describes a man's bicycle ride...\", \"skor_asli\": 2},\n            {\"nama\": \"Siswa 10\", \"jawaban\": \"In the story, 'Rough Road Ahead' written by Joe Kurmaskie...\", \"skor_asli\": 3},\n        ]\n    }\n\n# =====================================================\n# üîß STEP 2: LOAD MODELS (SMART SEARCH)\n# =====================================================\n\nprint(\"\\nüîÑ Loading SBERT model...\")\ntry:\n    encoder = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n    print(\"‚úÖ SBERT loaded!\")\nexcept Exception as e:\n    print(f\"‚ùå SBERT Error: {e}\")\n    encoder = None\n\nprint(\"\\nüîÑ Loading XGBoost Model...\")\n\nclass MyModel(torch.nn.Module):\n    def __init__(self, input_dim=384, hidden_dim=128, output_dim=1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n    def forward(self, x):\n        return self.fc2(self.relu(self.fc1(x)))\n\ndef find_model_path(filename):\n    if os.path.exists(filename): return filename\n    common_dirs = ['/kaggle/input', '/kaggle/working', '/content', 'models']\n    for d in common_dirs:\n        if os.path.exists(d):\n            for root, dirs, files in os.walk(d):\n                if filename in files: return os.path.join(root, filename)\n    return None\n\ndef load_best_model():\n    target_filename = \"eXtreme_Gradient_Boosting_(XGBoost).pkl\" \n    print(f\"üîé Mencari file: {target_filename} ...\")\n    model_path = find_model_path(target_filename)\n    \n    if model_path:\n        print(f\"‚úÖ Model ditemukan di: {model_path}\")\n        try:\n            data = joblib.load(model_path)\n            model = data.get('model', data) if isinstance(data, dict) else data\n            m_type = \"dl\" if isinstance(model, (torch.nn.Module, MyModel)) else \"ml\"\n            return model, m_type, 12.0 \n        except Exception as e:\n            print(f\"‚ùå Error loading pickle: {e}\")\n    else:\n        print(f\"‚ö†Ô∏è Model '{target_filename}' TIDAK DITEMUKAN.\")\n\n    print(\"‚ö†Ô∏è Menggunakan DUMMY Model (Random XGBoost).\")\n    dummy = XGBRegressor(random_state=42)\n    dummy.fit(np.random.rand(10, 384), np.random.rand(10) * 12)\n    return dummy, \"ml\", 12.0\n\nbest_model, model_type, model_max_score = load_best_model()\n\n# =====================================================\n# üß† STEP 3: GRADING FUNCTIONS\n# =====================================================\n\ndef grade_with_model_only(jawaban, kunci_jawaban):\n    if encoder is None: return 0.0\n    try:\n        emb_jawaban = encoder.encode([jawaban])\n        emb_kunci = encoder.encode([kunci_jawaban])\n        similarity = cosine_similarity(emb_jawaban, emb_kunci)[0][0]\n        \n        if model_type == \"ml\":\n            raw_pred = best_model.predict(emb_jawaban)[0]\n        else:\n            t = torch.tensor(emb_jawaban, dtype=torch.float32)\n            with torch.no_grad(): raw_pred = best_model(t).item()\n        \n        score_model = (float(raw_pred) / model_max_score) * 100\n        score_model = max(0.0, min(100.0, score_model))\n        final_score = (score_model * 0.5) + ((similarity * 100) * 0.5)\n        return round(final_score, 2)\n    except Exception as e:\n        return 0.0\n\ndef grade_with_llm_only(api_key, soal, kunci_jawaban, jawaban):\n    if not api_key or \"sk-\" not in api_key: return 0.0\n    try:\n        client = openai.OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=api_key)\n        prompt = f\"\"\"Kamu adalah Penilai Esai Otomatis.\nSOAL: {soal}\nKUNCI: {kunci_jawaban}\nJAWABAN SISWA: {jawaban}\nOutput HARUS JSON: {{\"skor\": <0-100>}}\"\"\"\n        response = client.chat.completions.create(\n            model=\"mistralai/mistral-7b-instruct:free\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            response_format={\"type\": \"json_object\"}, temperature=0.1\n        )\n        return float(json.loads(response.choices[0].message.content.strip()).get('skor', 0))\n    except: return 0.0\n\ndef grade_hybrid_50_50(api_key, soal, kunci_jawaban, jawaban):\n    s_model = grade_with_model_only(jawaban, kunci_jawaban)\n    s_llm = grade_with_llm_only(api_key, soal, kunci_jawaban, jawaban)\n    return round((s_model * 0.5) + (s_llm * 0.5), 2) if s_llm > 0 else s_model\n\n# =====================================================\n# üìä STEP 4: ADVANCED EVALUATION (MAE, MSE, RMSE, R2, QWK)\n# =====================================================\n\ndef calculate_detailed_metrics(y_true_100, y_pred_100, max_score_original):\n    \"\"\"\n    Menghitung 5 Metric Utama: MAE, MSE, RMSE, R2, QWK\n    \"\"\"\n    # 1. Konversi ke Numpy Array\n    y_true = np.array(y_true_100)\n    y_pred = np.array(y_pred_100)\n    \n    # 2. Metrics Continuous (Skala 0-100)\n    mae = mean_absolute_error(y_true, y_pred)\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(y_true, y_pred)\n    \n    # 3. Metrics Categorical/Ordinal (QWK)\n    # Kita harus convert balik 0-100 ke 0-3 (integer) untuk QWK\n    y_true_int = np.round((y_true / 100) * max_score_original).astype(int)\n    y_pred_int = np.round((y_pred / 100) * max_score_original).astype(int)\n    \n    # Clip agar tidak ada nilai di luar range (misal -1 atau 4)\n    y_pred_int = np.clip(y_pred_int, 0, max_score_original)\n    \n    qwk = cohen_kappa_score(y_true_int, y_pred_int, weights='quadratic')\n    \n    return mae, mse, rmse, r2, qwk\n\ndef evaluate_all_schemes(data, api_key):\n    soal = data[\"soal\"]\n    kunci = data[\"kunci_jawaban\"]\n    max_score = data[\"max_score\"]\n    siswa_data = data[\"data_siswa\"]\n    \n    # Lists untuk menampung semua nilai prediksi vs asli\n    y_true_list = []\n    y_pred_model = []\n    y_pred_llm = []\n    y_pred_hybrid = []\n    \n    results_table = []\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üöÄ STARTING EVALUATION LOOP...\")\n    print(\"=\"*80)\n    \n    for i, siswa in enumerate(siswa_data, 1):\n        nama = siswa[\"nama\"]\n        jawaban = siswa[\"jawaban\"]\n        skor_asli = siswa[\"skor_asli\"]\n        skor_asli_100 = (skor_asli / max_score) * 100\n        \n        print(f\"[{i}/{len(siswa_data)}] Grading {nama}...\")\n        \n        # Grading\n        val_model = grade_with_model_only(jawaban, kunci)\n        val_llm = grade_with_llm_only(api_key, soal, kunci, jawaban)\n        val_hybrid = grade_hybrid_50_50(api_key, soal, kunci, jawaban)\n        \n        # Simpan ke List untuk perhitungan global\n        y_true_list.append(skor_asli_100)\n        y_pred_model.append(val_model)\n        y_pred_llm.append(val_llm)\n        y_pred_hybrid.append(val_hybrid)\n        \n        results_table.append({\n            \"Nama\": nama,\n            \"Real (0-100)\": round(skor_asli_100, 1),\n            \"Model\": val_model,\n            \"LLM\": val_llm,\n            \"Hybrid\": val_hybrid\n        })\n\n    # --- HITUNG METRICS GLOBAL ---\n    metrics_data = []\n    \n    schemes = {\n        \"Model Only\": y_pred_model,\n        \"LLM Only\": y_pred_llm,\n        \"Hybrid\": y_pred_hybrid\n    }\n    \n    for name, preds in schemes.items():\n        mae, mse, rmse, r2, qwk = calculate_detailed_metrics(y_true_list, preds, max_score)\n        metrics_data.append({\n            \"Scheme\": name,\n            \"MAE (üìâ)\": round(mae, 2),\n            \"MSE (üìâ)\": round(mse, 2),\n            \"RMSE (üìâ)\": round(rmse, 2),\n            \"R2 Score (üìà)\": round(r2, 3),\n            \"QWK (üìà)\": round(qwk, 3)\n        })\n    \n    # Display Tables\n    df_results = pd.DataFrame(results_table)\n    df_metrics = pd.DataFrame(metrics_data)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üìä DETAIL NILAI PER SISWA\")\n    print(\"=\"*80)\n    print(df_results)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"üèÜ FINAL PERFORMANCE METRICS COMPARSION\")\n    print(\"=\"*80)\n    print(\"Keterangan:\")\n    print(\"üìâ : Semakin RENDAH semakin baik (Error)\")\n    print(\"üìà : Semakin TINGGI semakin baik (Akurasi/Korelasi)\")\n    print(\"-\" * 80)\n    print(df_metrics.to_string(index=False))\n    print(\"-\" * 80)\n    \n    # Penentuan Pemenang berdasarkan QWK (Standar AES)\n    best_scheme = df_metrics.loc[df_metrics['QWK (üìà)'].idxmax()]\n    print(f\"\\nüéâ WINNER (Based on QWK): {best_scheme['Scheme']}\")\n    print(f\"   QWK Score: {best_scheme['QWK (üìà)']}\")\n    \n    return df_metrics\n\n# =====================================================\n# üöÄ MAIN EXECUTION\n# =====================================================\n\nMY_API_KEY = \"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\" \n\nif __name__ == \"__main__\":\n    data_input = input_manual()\n    df_final = evaluate_all_schemes(data_input, MY_API_KEY)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =======================================================\n# üéØ HYBRID AI GRADING SYSTEM (50-50 VERSION)\n# =======================================================\n\nimport gradio as gr\nimport joblib\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport openai\nimport json\nimport os\nimport torch\nimport torch.nn as nn\nfrom sentence_transformers import SentenceTransformer\nfrom xgboost import XGBRegressor\nfrom typing import Tuple, Dict, Any\n\nprint(\"=\"*60)\nprint(\"üöÄ INITIALIZING HYBRID 50-50 GRADING SYSTEM\")\nprint(\"=\"*60)\n\n# =====================================================\n# üîß 1. LOAD SBERT MODEL\n# =====================================================\n\nprint(\"\\nüîÑ Loading SBERT model...\")\ntry:\n    # Menggunakan model yang relatif ringan dan cepat\n    encoder = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n    print(\"‚úÖ SBERT model loaded successfully!\")\nexcept Exception as e:\n    print(f\"‚ùå Error loading SBERT: {e}\")\n    # Fatal jika encoder gagal dimuat karena diperlukan untuk Technical Score\n    encoder = None\n    exit()\n\n# =====================================================\n# üîß 2. PLACEHOLDER DL MODEL CLASS\n# =====================================================\n\nclass MyModel(torch.nn.Module):\n    \"\"\"Model placeholder untuk PyTorch/DL\"\"\"\n    def __init__(self, input_dim=384, hidden_dim=128, output_dim=1):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        return self.fc2(x)\n\n# =====================================================\n# üîß 3. LOAD TRAINED MODEL (ML/DL)\n# =====================================================\n\ndef get_dummy_model() -> Tuple[Any, str, float]:\n    \"\"\"Fallback jika model tidak ditemukan (XGBoost sebagai placeholder)\"\"\"\n    print(\"‚ö†Ô∏è Model asli tidak ditemukan, menggunakan DUMMY Model\")\n    dummy = XGBRegressor(random_state=42)\n    # Fit model dummy dengan data random (384 = SBERT embedding dim)\n    dummy.fit(np.random.rand(10, 384), np.random.rand(10) * 12)\n    # Model dummy memprediksi skor maksimal 12.0\n    return dummy, \"ml\", 12.0\n\ndef load_custom_model() -> Tuple[Any, str, float]:\n    \"\"\"Memuat model terbaik (.pkl untuk ML, .pth untuk DL)\"\"\"\n    model_dir = \"models\"\n    \n    if not os.path.exists(model_dir):\n        os.makedirs(model_dir, exist_ok=True)\n        return get_dummy_model()\n        \n    try:\n        files = os.listdir(model_dir)\n        \n        # Cari file model terbaik (.pkl atau .pth)\n        best_pkl = next((os.path.join(model_dir, f) for f in files if \"BEST_MODEL\" in f and f.endswith(\".pkl\")), None)\n        best_pth = next((os.path.join(model_dir, f) for f in files if \"BEST_MODEL\" in f and f.endswith(\".pth\")), None)\n        \n        if best_pkl:\n            print(f\"üöÄ Loading ML Model: {best_pkl}\")\n            data = joblib.load(best_pkl)\n            # Menangani jika joblib menyimpan dict (mis. {'model': model})\n            model = data.get('model', data.get('estimator', data)) if isinstance(data, dict) else data\n            if model is None:\n                print(\"‚ùå Model tidak ditemukan dalam dict\")\n                return get_dummy_model()\n            print(\"‚úÖ ML Model loaded successfully!\")\n            # Asumsi skor maksimal model ini adalah 100.0 (sesuaikan dengan model training Anda!)\n            return model, \"ml\", 100.0 \n            \n        if best_pth:\n            print(f\"üöÄ Loading DL Model: {best_pth}\")\n            model = MyModel() # Inisiasi model DL\n            checkpoint = torch.load(best_pth, map_location=\"cpu\")\n            # Menangani jika torch.save menyimpan dict (mis. {'model_state_dict': state})\n            state_dict = checkpoint.get('model_state_dict', checkpoint) if isinstance(checkpoint, dict) else checkpoint\n            model.load_state_dict(state_dict)\n            model.eval()\n            print(\"‚úÖ DL Model loaded successfully!\")\n            # Asumsi skor maksimal model ini adalah 100.0 (sesuaikan dengan model training Anda!)\n            return model, \"dl\", 100.0\n            \n        return get_dummy_model()\n        \n    except Exception as e:\n        print(f\"‚ùå Error loading model: {e}\")\n        return get_dummy_model()\n\n# Load model global\nbest_model, model_type, model_max_score = load_custom_model()\nprint(f\"\\nüìä Model Type: {model_type.upper()}\")\nprint(f\"üìä Max Score Range: 0-{model_max_score}\")\n\n# =====================================================\n# üß† 4. OPENROUTER LLM CHECKER\n# =====================================================\n\ndef cek_konteks_llm(api_key: str, soal: str, kunci: str, jawaban_mhs: str) -> Tuple[float, str]:\n    \"\"\"Menggunakan LLM (OpenRouter) untuk penilaian kontekstual/logika.\"\"\"\n    if not api_key or not api_key.strip() or not jawaban_mhs.strip():\n        return 0.0, \"‚ö†Ô∏è API Key/Jawaban kosong. Mode Offline/Fallback aktif.\"\n    \n    try:\n        client = openai.OpenAI(\n            base_url=\"https://openrouter.ai/api/v1\",\n            api_key=api_key,\n        )\n\n        # Menggunakan model Mistral yang gratis\n        OPENROUTER_MODEL = \"mistralai/mistral-7b-instruct:free\" \n        \n        prompt = f\"\"\"\nKamu adalah Dosen Penilai yang Objektif dan Teliti.\n\n**SOAL:**\n{soal}\n\n**KUNCI JAWABAN (Reference):**\n{kunci}\n\n**JAWABAN MAHASISWA:**\n{jawaban_mhs}\n\n**TUGAS:**\nBerikan penilaian objektif berdasarkan kriteria: Relevansi (40%), Kebenaran (40%), Kelengkapan (20%).\nHanya beri skor rendah jika benar-benar salah/tidak relevan.\n\n**OUTPUT (WAJIB FORMAT JSON):**\n{{\"skor\": <integer 0-100>, \"alasan\": \"<penjelasan singkat 1-2 kalimat>\"}}\n\"\"\"\n        \n        response = client.chat.completions.create(\n            model=OPENROUTER_MODEL,\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are an objective essay grader. Your output must be a single JSON object. Only output the JSON.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            response_format={\"type\": \"json_object\"}, \n            temperature=0.3\n        )\n        \n        text_res = response.choices[0].message.content.strip()\n        data = json.loads(text_res)\n        skor = max(0.0, min(100.0, float(data.get('skor', 0))))\n        alasan = data.get('alasan', 'Tidak ada feedback')\n        return skor, alasan\n        \n    except json.JSONDecodeError:\n        import re\n        # Fallback parsing jika JSON response tidak sempurna\n        match = re.search(r'\"skor\"\\s*:\\s*(\\d+)', text_res)\n        if match:\n            skor = max(0.0, min(100.0, float(match.group(1))))\n            return skor, \"Feedback parsing error, skor diekstrak manual.\"\n        else:\n            return 0.0, f\"‚ö†Ô∏è Gagal parse response OpenRouter: {text_res[:100]}... | Error: JSONDecodeError\"\n            \n    except openai.APIError as e:\n        error_msg = str(e)\n        if \"rate limit\" in error_msg.lower() or \"429\" in error_msg:\n             return 0.0, \"‚ùå OpenRouter Error: Quota/Rate Limit habis. Mode fallback aktif.\"\n        elif \"authentication\" in error_msg.lower() or \"401\" in error_msg:\n             return 0.0, \"‚ùå OpenRouter Error: API Key tidak valid. Mode fallback aktif.\"\n        print(f\"‚ùå OpenRouter API Error: {error_msg}\")\n        return 0.0, f\"‚ùå OpenRouter Error: {error_msg[:50]}... | Mode fallback aktif.\"\n\n    except Exception as e:\n        error_msg = str(e)\n        print(f\"‚ùå Unexpected OpenRouter Error: {error_msg}\")\n        return 0.0, f\"‚ùå Error tak terduga: {error_msg[:50]}... | Mode fallback aktif.\"\n\n\n# =====================================================\n# üéØ 5. HYBRID 50-50 GRADING FUNCTION\n# =====================================================\n\ndef grade_essay_hybrid(api_key: str, jawaban_mahasiswa: str, current_state: Dict[str, Any]) -> Tuple[float, float, float, str, str]:\n    \"\"\"Fungsi utama untuk penilaian hybrid 50-50.\"\"\"\n    if not jawaban_mahasiswa or not jawaban_mahasiswa.strip():\n        return 0.0, 0.0, 0.0, \"Jawaban kosong\", \"N/A\"\n        \n    soal = current_state.get(\"soal\", \"\")\n    kunci_jawaban = current_state.get(\"jawaban_benar\", \"\")\n    max_score_dosen = current_state.get(\"max_score\", 100.0)\n    \n    score_technical = 0.0\n    similarity = 0.0\n    \n    # STEP 1: TECHNICAL SCORING (Model-based)\n    if not kunci_jawaban or not kunci_jawaban.strip():\n        # Jika kunci jawaban kosong, Technical Score dan Similarity tidak dihitung (dianggap 0)\n        print(\"‚ö†Ô∏è Kunci Jawaban kosong. Technical Score/Similarity diatur ke 0.\")\n    else:\n        try:\n            emb_mhs = encoder.encode([jawaban_mahasiswa])\n            emb_kunci = encoder.encode([kunci_jawaban])\n            \n            # 1. Similarity\n            similarity = cosine_similarity(emb_mhs, emb_kunci)[0][0]\n            similarity = max(0.0, similarity)\n            \n            # 2. Model Prediction\n            if model_type == \"ml\":\n                raw_pred = best_model.predict(emb_mhs)[0]\n            else:\n                t_mhs = torch.tensor(emb_mhs, dtype=torch.float32)\n                with torch.no_grad():\n                    raw_pred = best_model(t_mhs).item()\n            \n            # 3. Normalisasi Skor Teknis ke skala 0-100\n            score_technical = (float(raw_pred) / model_max_score) * 100\n            score_technical = max(0.0, min(100.0, score_technical))\n            \n            # Jika similarity mendekati sempurna, beri skor 100.0\n            if similarity > 0.99:\n                score_technical = 100.0\n        \n        except Exception as e:\n            print(f\"‚ùå Technical scoring error: {e}\")\n            score_technical = 0.0\n            similarity = 0.0\n            \n    # STEP 2: LOGICAL SCORING (LLM-based)\n    score_llm, feedback_llm = cek_konteks_llm(api_key, soal, kunci_jawaban, jawaban_mahasiswa)\n    \n    # STEP 3: FINAL SCORE CALCULATION (50-50)\n    \n    # LLM dianggap sukses jika API Key ada dan tidak ada error fatal/auth/rate limit di feedback\n    is_llm_success = not (\"Error\" in feedback_llm or \"Offline/Fallback aktif\" in feedback_llm or \"Key tidak valid\" in feedback_llm) and api_key.strip()\n    \n    if is_llm_success:\n        # üéØ HYBRID MODE 50-50: 50% Model + 50% LLM\n        final_score_raw = (score_technical * 0.5) + (score_llm * 0.5)\n        mode_used = \"üü¢ Hybrid 50-50 (Model+AI)\"\n    else:\n        # OFFLINE MODE (Fallback tanpa LLM)\n        \n        # Hitung Similarity Score (0-100)\n        similarity_score = similarity * 100\n        \n        if not kunci_jawaban or not kunci_jawaban.strip():\n            # Jika kunci jawaban kosong, hanya andalkan Technical Score (Model ML/DL)\n            final_score_raw = score_technical\n            mode_used = \"üü° Full Offline (Tech Model Only)\"\n        else:\n            # Fallback normal: 50% Technical Score + 50% Similarity Score\n            final_score_raw = (score_technical * 0.5) + (similarity_score * 0.5)\n            mode_used = \"üü° Offline (Model+Sim)\"\n            \n    # Scale final score (0-100) ke max_score dosen\n    final_score = (final_score_raw / 100.0) * max_score_dosen\n    final_score = max(0.0, min(max_score_dosen, final_score))\n    \n    return (\n        round(final_score, 2),\n        round(score_technical, 2), # Technical score (0-100)\n        round(score_llm, 2),       # LLM score (0-100)\n        feedback_llm,\n        mode_used\n    )\n\n# =====================================================\n# üóÇÔ∏è 6. GRADIO UI LOGIC FUNCTIONS\n# =====================================================\n\ndef simpan_soal(soal: str, jawaban_benar: str, max_score: float, state: Dict[str, Any]) -> Tuple[Dict[str, Any], str, pd.DataFrame]:\n    \"\"\"Handler untuk tombol Simpan Soal\"\"\"\n    if not soal or not soal.strip() or not jawaban_benar or not jawaban_benar.strip():\n        empty_df = pd.DataFrame(columns=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\", \"Mode\", \"Feedback\"])\n        return state, \"‚ùå Soal/Kunci Jawaban tidak boleh kosong!\", empty_df\n    \n    try:\n        max_score_float = float(max_score)\n    except (ValueError, TypeError):\n        max_score_float = 100.0\n\n    new_state = {\n        \"soal\": soal,\n        \"jawaban_benar\": jawaban_benar,\n        \"max_score\": max_score_float,\n        \"leaderboard\": pd.DataFrame(columns=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\", \"Mode\", \"Feedback\"])\n    }\n    \n    status_msg = f\"‚úÖ Soal tersimpan!\\nüìù Soal: {soal[:50]}...\\nüéØ Max Score: {new_state['max_score']}\"\n    \n    return new_state, status_msg, new_state[\"leaderboard\"]\n\n\ndef submit_jawaban_hybrid(api_key: str, nama: str, jawaban: str, state: Dict[str, Any]) -> Tuple[Dict[str, Any], pd.DataFrame, str]:\n    \"\"\"Handler untuk tombol Submit Jawaban\"\"\"\n    # 1. Cek Ketersediaan Soal\n    if not state or \"soal\" not in state or not state[\"soal\"]:\n        return state, state.get(\"leaderboard\", pd.DataFrame()), \"‚ö†Ô∏è **Error:** Dosen belum membuat soal!\"\n    \n    # 2. Cek Input Mahasiswa\n    if not nama or not nama.strip():\n        return state, state.get(\"leaderboard\", pd.DataFrame()), \"‚ö†Ô∏è **Error:** Nama harus diisi!\"\n    \n    if not jawaban or not jawaban.strip():\n        return state, state.get(\"leaderboard\", pd.DataFrame()), \"‚ö†Ô∏è **Error:** Jawaban harus diisi!\"\n    \n    # 3. Grading\n    total, teknis, logika, feedback, mode = grade_essay_hybrid(api_key, jawaban, state)\n    \n    # 4. Update leaderboard\n    df = state.get(\"leaderboard\", pd.DataFrame(columns=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\", \"Mode\", \"Feedback\"]))\n    \n    new_row = {\n        \"Nama\": nama, \"Total\": total, \"Teknis\": teknis, \n        \"Logika(AI)\": logika, \"Mode\": mode, \"Feedback\": feedback\n    }\n    \n    # Cek dan update/tambah row\n    if not df.empty and nama in df[\"Nama\"].values:\n        df.loc[df[\"Nama\"] == nama, list(new_row.keys())] = list(new_row.values())\n    else:\n        new_df = pd.DataFrame([new_row])\n        df = pd.concat([df, new_df], ignore_index=True)\n    \n    # Urutkan berdasarkan skor tertinggi\n    df = df.sort_values(by=\"Total\", ascending=False).reset_index(drop=True)\n    state[\"leaderboard\"] = df\n    \n    # 5. Format feedback message\n    max_score = state.get(\"max_score\", 100.0)\n    emoji = \"üìö\"\n    grade = \"Perlu Belajar\"\n    if total >= max_score * 0.9:\n        emoji = \"üåü\"\n        grade = \"Sempurna!\"\n    elif total >= max_score * 0.7:\n        emoji = \"‚úÖ\"\n        grade = \"Bagus!\"\n    elif total >= max_score * 0.5:\n        emoji = \"üëç\"\n        grade = \"Cukup\"\n    \n    msg = f\"\"\"\n### {emoji} Hasil Penilaian: **{nama}**\n---\n**üèÜ SKOR AKHIR: {total} / {max_score}** ({grade})\nüìä **Rincian Penilaian (Skala 0-100):**\n- ü§ñ **Teknis (Model):** {teknis} (Bobot 50%)\n- üß† **Logika (AI):** {logika} (Bobot 50%)\n---\nüí° **Feedback AI:** > {feedback}\nüîß **Mode:** {mode}\n---\n\"\"\"\n    # Kolom Feedback disembunyikan di leaderboard mahasiswa\n    return state, df.drop(columns=[\"Feedback\"], errors='ignore'), msg\n\n\ndef tampilkan_soal(state: Dict[str, Any]) -> str:\n    \"\"\"Tampilkan soal di tab mahasiswa\"\"\"\n    if state and \"soal\" in state and state[\"soal\"]:\n        return f\"üìã **Soal:**\\n\\n{state['soal']}\"\n    return \"‚ö†Ô∏è _(Dosen belum membuat soal)_\"\n\n# =====================================================\n# üé® 7. GRADIO UI\n# =====================================================\n\nwith gr.Blocks(title=\"Hybrid 50-50 Grader\") as demo:\n    initial_state = {\n        \"soal\": None, \"jawaban_benar\": None, \"max_score\": 100.0,\n        \"leaderboard\": pd.DataFrame(columns=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\", \"Mode\", \"Feedback\"])\n    }\n    state = gr.State(initial_state)\n    \n    gr.Markdown(\"\"\"\n    # üöÄ Hybrid 50-50 Essay Grading System\n    ### Sistem Penilaian Esai dengan Bobot Seimbang: 50% Model + 50% LLM\n    ---\n    \"\"\")\n    \n    # API Key Setup\n    with gr.Accordion(\"üîë Setup API Key OpenRouter (Required for Hybrid Mode)\", open=False):\n        gr.Markdown(\"\"\"\n        **Cara Mendapatkan API Key OpenRouter:** [OpenRouter Dashboard](https://openrouter.ai/keys)\n        ‚ö†Ô∏è **Tanpa API Key:** Sistem akan fallback ke Model + Similarity.\n        \"\"\")\n        api_key_input = gr.Textbox(\n            label=\"OpenRouter API Key\", type=\"password\", placeholder=\"sk-or-v1-...\", \n            info=\"Key ini TIDAK akan disimpan.\"\n        )\n    \n    with gr.Tabs():\n        # TAB 1: PORTAL DOSEN\n        with gr.Tab(\"üë®‚Äçüè´ Portal Dosen\"):\n            gr.Markdown(\"### Buat Soal & Kunci Jawaban\")\n            \n            with gr.Row():\n                with gr.Column(scale=2):\n                    soal_in = gr.Textbox(label=\"üìù Soal Essay\", lines=3, placeholder=\"Jelaskan dampak AI pada pendidikan modern...\")\n                    kunci_in = gr.Textbox(label=\"‚úÖ Kunci Jawaban (Referensi Ideal)\", lines=8, placeholder=\"Tuliskan jawaban ideal...\")\n                \n                with gr.Column(scale=1):\n                    max_score = gr.Number(value=100, label=\"üéØ Skor Maksimal\")\n                    btn_save = gr.Button(\"üíæ Simpan Soal\", variant=\"primary\", size=\"lg\")\n                    status_dosen = gr.Textbox(label=\"üìä Status\", interactive=False, lines=3)\n            \n            gr.Markdown(\"---\")\n            gr.Markdown(\"### üìä Preview Leaderboard (Dosen)\")\n            leaderboard_dosen = gr.DataFrame(label=\"Leaderboard (Live)\", interactive=False)\n            \n            btn_save.click(\n                fn=simpan_soal,\n                inputs=[soal_in, kunci_in, max_score, state],\n                outputs=[state, status_dosen, leaderboard_dosen]\n            )\n        \n        # TAB 2: PORTAL MAHASISWA\n        with gr.Tab(\"üßë‚Äçüéì Portal Mahasiswa\") as mahasiswa_tab:\n            gr.Markdown(\"### Lihat Soal & Submit Jawaban\")\n            \n            soal_display = gr.Markdown(value=\"‚ö†Ô∏è _(Dosen belum membuat soal)_\")\n            \n            with gr.Row():\n                with gr.Column(scale=2):\n                    nama_in = gr.Textbox(label=\"üë§ Nama Lengkap\", placeholder=\"Contoh: Budi Santoso\")\n                    jawab_in = gr.Textbox(label=\"‚úçÔ∏è Jawaban Kamu\", lines=10, placeholder=\"Tuliskan jawabanmu di sini...\")\n                    btn_submit = gr.Button(\"üöÄ Kirim Jawaban\", variant=\"primary\", size=\"lg\")\n                \n                with gr.Column(scale=1):\n                    gr.Markdown(\"### üèÜ Live Leaderboard\")\n                    # Kolom Feedback disembunyikan di tampilan Mahasiswa\n                    lb_mhs = gr.DataFrame(label=\"Top Scores\", interactive=False, headers=[\"Nama\", \"Total\", \"Teknis\", \"Logika(AI)\"])\n            \n            gr.Markdown(\"---\")\n            status_mhs = gr.Markdown(value=\"_Isi form di atas dan klik 'Kirim Jawaban'_\")\n            \n            btn_submit.click(\n                fn=submit_jawaban_hybrid,\n                inputs=[api_key_input, nama_in, jawab_in, state],\n                outputs=[state, lb_mhs, status_mhs]\n            )\n            \n            # Update tampilan soal saat tab Mahasiswa dipilih\n            mahasiswa_tab.select(\n                fn=tampilkan_soal,\n                inputs=[state],\n                outputs=[soal_display]\n            )\n\n# =====================================================\n# üöÄ 8. LAUNCH APPLICATION\n# =====================================================\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ SYSTEM READY!\")\nprint(\"=\"*60)\nprint(f\"üìä Model Type: {model_type.upper()}\")\nprint(f\"ü§ñ SBERT: {'‚úÖ Loaded' if encoder else '‚ùå Failed'}\")\nprint(f\"üß† LLM: OpenRouter (via Mistral 7B)\")\nprint(f\"‚öñÔ∏è Scoring Weight: 50% Model + 50% LLM\")\nprint(\"=\"*60)\nprint(\"\\nüöÄ Launching Gradio interface...\\n\")\n\ndemo.launch(share=True, debug=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}